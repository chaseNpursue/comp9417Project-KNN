{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Onur Alp Bicer\n",
    "#         Shengian (sorry i don't know your last name)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# floating point percentage of the data to use as training data, rest will be used as test data\n",
    "split_ratio = 0.8\n",
    "\n",
    "# k \n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute mappings for Automobile dataset\n",
    "def getDict(list_attr):\n",
    "    nums = range(len(list_attr))\n",
    "    return dict(zip(list_attr, nums))\n",
    "\n",
    "make = getDict(['alfa-romero', 'audi', 'bmw', 'chevrolet', 'dodge', 'honda', 'isuzu', 'jaguar', 'mazda', \n",
    "        'mercedes-benz', 'mercury', 'mitsubishi', 'nissan', 'peugot', 'plymouth', 'porsche',\n",
    "        'renault', 'saab', 'subaru', 'toyota', 'volkswagen', 'volvo'])\n",
    "\n",
    "fuel_type = getDict(['diesel', 'gas'])\n",
    "aspiration = getDict(['std', 'turbo'])\n",
    "num_doors = getDict(['four', 'two'])\n",
    "num_doors['?'] = -1\n",
    "\n",
    "body_style = getDict(['hardtop', 'wagon', 'sedan', 'hatchback', 'convertible'])\n",
    "\n",
    "drive_wheels = getDict(['4wd', 'fwd', 'rwd'])\n",
    "\n",
    "engine_location = getDict(['front', 'rear'])\n",
    "engine_type = getDict(['dohc', 'dohcv', 'l', 'ohc', 'ohcf', 'ohcv', 'rotor'])\n",
    "num_cylinders = getDict(['eight', 'five', 'four', 'six', 'three', 'twelve', 'two'])\n",
    "fuel_system = getDict(['1bbl', '2bbl', '4bbl', 'idi', 'mfi', 'mpfi', 'spdi', 'spfi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to split data\n",
    "def split_data(data, split_ratio):\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    n = int(split_ratio * len(data))\n",
    "    train_data_X = data[:n,:-1]\n",
    "    train_data_Y = data[:n, -1]\n",
    "    test_data_X = data[n:, :-1]\n",
    "    test_data_Y = data[n:, -1]\n",
    "    \n",
    "    return train_data_X, train_data_Y, test_data_X, test_data_Y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack data from ionosphere data by UCI https://archive.ics.uci.edu/ml/datasets/ionosphere\n",
    "def getIonosphereData(split_ratio):\n",
    "    data = []\n",
    "    with open('ionosphere.data') as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            if row[34] == 'g':\n",
    "                row[34] = 1\n",
    "            elif row[34] == 'b':\n",
    "                row[34] =  0\n",
    "            else:\n",
    "                print(\"Unknown label encountered while parsing dataset\")\n",
    "                exit(1)\n",
    "            data.append(np.asarray(row, dtype=float))\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "#     return split_data(data, split_ratio)\n",
    "    return data[:,:-1], data[:, -1]\n",
    "    \n",
    "# train_data_X, train_data_Y, test_data_X, test_data_Y = getIonosphereData(split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack data from automobile data by UCI https://archive.ics.uci.edu/ml/datasets/automobile\n",
    "def getAutomobileData(split_ratio, noncontinuous=False):\n",
    "    data = []\n",
    "    \n",
    "    with open('imports-85.data') as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',')\n",
    "        if noncontinuous == True:\n",
    "            for row in csv_reader:\n",
    "                add = True\n",
    "                row[2] = make[row[2]] \n",
    "                row[3] = fuel_type[row[3]]\n",
    "                row[4] = aspiration[row[4]]\n",
    "                row[5] = num_doors[row[5]]\n",
    "                row[6] = body_style[row[6]]\n",
    "                row[7] = drive_wheels[row[7]]\n",
    "                row[8] = engine_location[row[8]]\n",
    "                row[14] = engine_type[row[14]]\n",
    "                row[15] = num_cylinders[row[15]]\n",
    "                row[17] = fuel_system[row[17]]\n",
    "\n",
    "                for i in range(len(row)):\n",
    "                    if row[i] == '?':\n",
    "                        add = False\n",
    "\n",
    "                if add == True:\n",
    "                    data.append(np.asarray(row, dtype=float))\n",
    "                    \n",
    "        elif noncontinuous == False:\n",
    "            for row in csv_reader:\n",
    "                add = True\n",
    "                row = [row[0], row[1], row[9], row[10], row[11], row[12], row[13], row[16], row[18],\n",
    "                       row[19], row[20], row[21], row[22], row[23], row[24], row[25]]\n",
    "                \n",
    "                for i in range(len(row)):\n",
    "                    if row[i] == '?':\n",
    "                        add = False\n",
    "\n",
    "                if add == True:\n",
    "                    data.append(np.asarray(row, dtype=float))\n",
    "        else:\n",
    "            print(\"Unknown parameter\")\n",
    "            exit(1)\n",
    "            \n",
    "    data = np.array(data)\n",
    "    \n",
    "#     return split_data(data, split_ratio)\n",
    "    return data[:,:-1], data[:, -1]\n",
    "    \n",
    "# train_data_X, train_data_Y, test_data_X, test_data_Y = getAutomobileData(split_ratio, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://math.stackexchange.com/questions/139600/how-do-i-calculate-euclidean-and-manhattan-distance-by-hand\n",
    "\n",
    "# This function returns the pairwise manhattan distance of 2 points in n dimensions(formula on the link above)\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.abs((x1 - x2)).sum()\n",
    "    \n",
    "# This function returns the pairwise euclidean distance of 2 points in n dimensions(formula on the link above)\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.square((x1 - x2)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Euclidean Distance for (0,0) and (3,4) = 5\n",
      "Actual Euclidean Distance = 5.0\n",
      "\n",
      "Expected Manhattan Distance for (0,0) and (3,4) = 7\n",
      "Actual Manhattan Distance = 7\n"
     ]
    }
   ],
   "source": [
    "# Testing the distances\n",
    "x1 = np.array([0, 0])\n",
    "x2 = np.array([3, 4])\n",
    "print(\"Expected Euclidean Distance for (0,0) and (3,4) = 5\")\n",
    "print(\"Actual Euclidean Distance = \" + str(euclidean_distance(x1, x2)))\n",
    "print(\"\\nExpected Manhattan Distance for (0,0) and (3,4) = 7\")\n",
    "print(\"Actual Manhattan Distance = \" + str(manhattan_distance(x1, x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get first element of a list to use for sorting\n",
    "def getFirstElement(val):\n",
    "    return val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode for algorithm in the following website \n",
    "# https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n",
    "def knn(X_train, Y_train, X_test, k=5, distance='Euclidean'):\n",
    "    vals = []\n",
    "    for i in range(len(X_train)):\n",
    "        if distance == 'Euclidean':\n",
    "            d = euclidean_distance(X_train[i], X_test)\n",
    "        elif distance == 'Manhattan':\n",
    "            d = manhattan_distance(X_train[i], X_test)\n",
    "        else:\n",
    "            print(\"Unknown distance\")\n",
    "            exit(1)\n",
    "            \n",
    "        vals.append([d, Y_train[i]])\n",
    "        \n",
    "    vals.sort(key=getFirstElement)\n",
    "    preds = np.asarray(vals)[:k, -1] \n",
    "    unique_elem, freq = np.unique(preds, return_counts=True)\n",
    "\n",
    "    return unique_elem[freq.argmax()]\n",
    "       \n",
    "# Test\n",
    "# knn(train_data_X, train_data_Y, test_data_X[0], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for classification by Leave One Out Cross Validation is 0.12535612535612536\n"
     ]
    }
   ],
   "source": [
    "# Classification task\n",
    "def classify(k):\n",
    "    data_X, data_Y = getIonosphereData(split_ratio)\n",
    "\n",
    "    err = 0\n",
    "    for i in range(len(data_X)):\n",
    "        x_in = np.concatenate((data_X[:i], data_X[i:]))\n",
    "        y_in = np.concatenate((data_Y[:i], data_Y[i:]))\n",
    "        x_out = data_X[i]\n",
    "        y_out = knn(x_in, y_in, x_out, k)\n",
    "        err += np.square(data_Y[i] - y_out)\n",
    "        \n",
    "    err = err/len(data_X)    \n",
    "\n",
    "    print(\"Error for classification by Leave One Out Cross Validation is \" + str(err))\n",
    "    \n",
    "classify(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
